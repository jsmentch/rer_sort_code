{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2d781a-20fc-4af4-947f-4d5eedb4e4ae",
   "metadata": {},
   "source": [
    "# notebook to run coqui on all of the RER item_names to estimate their length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2954a03e-9d1e-400e-9874-cab246c75d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1edbf4-e611-4ce0-b865-8cb07bc5a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tts_models/multilingual/multi-dataset/xtts_v2', 'tts_models/multilingual/multi-dataset/xtts_v1.1', 'tts_models/multilingual/multi-dataset/your_tts', 'tts_models/multilingual/multi-dataset/bark', 'tts_models/bg/cv/vits', 'tts_models/cs/cv/vits', 'tts_models/da/cv/vits', 'tts_models/et/cv/vits', 'tts_models/ga/cv/vits', 'tts_models/en/ek1/tacotron2', 'tts_models/en/ljspeech/tacotron2-DDC', 'tts_models/en/ljspeech/tacotron2-DDC_ph', 'tts_models/en/ljspeech/glow-tts', 'tts_models/en/ljspeech/speedy-speech', 'tts_models/en/ljspeech/tacotron2-DCA', 'tts_models/en/ljspeech/vits', 'tts_models/en/ljspeech/vits--neon', 'tts_models/en/ljspeech/fast_pitch', 'tts_models/en/ljspeech/overflow', 'tts_models/en/ljspeech/neural_hmm', 'tts_models/en/vctk/vits', 'tts_models/en/vctk/fast_pitch', 'tts_models/en/sam/tacotron-DDC', 'tts_models/en/blizzard2013/capacitron-t2-c50', 'tts_models/en/blizzard2013/capacitron-t2-c150_v2', 'tts_models/en/multi-dataset/tortoise-v2', 'tts_models/en/jenny/jenny', 'tts_models/es/mai/tacotron2-DDC', 'tts_models/es/css10/vits', 'tts_models/fr/mai/tacotron2-DDC', 'tts_models/fr/css10/vits', 'tts_models/uk/mai/glow-tts', 'tts_models/uk/mai/vits', 'tts_models/zh-CN/baker/tacotron2-DDC-GST', 'tts_models/nl/mai/tacotron2-DDC', 'tts_models/nl/css10/vits', 'tts_models/de/thorsten/tacotron2-DCA', 'tts_models/de/thorsten/vits', 'tts_models/de/thorsten/tacotron2-DDC', 'tts_models/de/css10/vits-neon', 'tts_models/ja/kokoro/tacotron2-DDC', 'tts_models/tr/common-voice/glow-tts', 'tts_models/it/mai_female/glow-tts', 'tts_models/it/mai_female/vits', 'tts_models/it/mai_male/glow-tts', 'tts_models/it/mai_male/vits', 'tts_models/ewe/openbible/vits', 'tts_models/hau/openbible/vits', 'tts_models/lin/openbible/vits', 'tts_models/tw_akuapem/openbible/vits', 'tts_models/tw_asante/openbible/vits', 'tts_models/yor/openbible/vits', 'tts_models/hu/css10/vits', 'tts_models/el/cv/vits', 'tts_models/fi/css10/vits', 'tts_models/hr/cv/vits', 'tts_models/lt/cv/vits', 'tts_models/lv/cv/vits', 'tts_models/mt/cv/vits', 'tts_models/pl/mai_female/vits', 'tts_models/pt/cv/vits', 'tts_models/ro/cv/vits', 'tts_models/sk/cv/vits', 'tts_models/sl/cv/vits', 'tts_models/sv/cv/vits', 'tts_models/ca/custom/vits', 'tts_models/fa/custom/glow-tts', 'tts_models/bn/custom/vits-male', 'tts_models/bn/custom/vits-female', 'tts_models/be/common-voice/glow-tts', 'vocoder_models/universal/libri-tts/wavegrad', 'vocoder_models/universal/libri-tts/fullband-melgan', 'vocoder_models/en/ek1/wavegrad', 'vocoder_models/en/ljspeech/multiband-melgan', 'vocoder_models/en/ljspeech/hifigan_v2', 'vocoder_models/en/ljspeech/univnet', 'vocoder_models/en/blizzard2013/hifigan_v2', 'vocoder_models/en/vctk/hifigan_v2', 'vocoder_models/en/sam/hifigan_v2', 'vocoder_models/nl/mai/parallel-wavegan', 'vocoder_models/de/thorsten/wavegrad', 'vocoder_models/de/thorsten/fullband-melgan', 'vocoder_models/de/thorsten/hifigan_v1', 'vocoder_models/ja/kokoro/hifigan_v1', 'vocoder_models/uk/mai/multiband-melgan', 'vocoder_models/tr/common-voice/hifigan', 'vocoder_models/be/common-voice/hifigan', 'voice_conversion_models/multilingual/vctk/freevc24']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "# Get device\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "# List available 🐸TTS models\n",
    "tts_manager = TTS().list_models()\n",
    "all_models = tts_manager.list_models()\n",
    "print(all_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81459658-bf88-47ac-8df3-1e560f29df4a",
   "metadata": {},
   "source": [
    "## try a quick model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb94566-b865-414a-a1b1-cc0299507017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init TTS with the target model name\n",
    "tts = TTS(model_name='tts_models/en/ljspeech/speedy-speech', progress_bar=False).to(device)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"Testing, Hello how are you?.\", file_path='./output.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9d724-b339-4c5b-af76-94b65b654189",
   "metadata": {},
   "source": [
    "## Try a fancy model! on a real kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efef1ca-aeba-4aac-8d93-877e1de85e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > You must confirm the following:\n",
      " | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"\n",
      " | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " | | >  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading model to /home/jsmentch/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋| 1.87G/1.87G [00:26<00:00, 70.5MiB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.87G/1.87G [00:28<00:00, 64.7MiB/s]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.37k/4.37k [00:00<00:00, 12.3kiB/s]\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 361k/361k [00:00<00:00, 903kiB/s]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32.0/32.0 [00:00<00:00, 72.7iB/s]\n",
      " 50%|████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                | 3.88M/7.75M [00:00<00:00, 38.8MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model's license - CPML\n",
      " > Check https://coqui.ai/cpml.txt for more info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/jsmentch/anaconda/envs/coqui/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/om2/user/jsmentch/anaconda/envs/coqui/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Using model: xtts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.75M/7.75M [00:19<00:00, 38.8MiB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Hello world!']\n",
      " > Processing time: 10.516849756240845\n",
      " > Real-time factor: 4.3537199069748915\n",
      " > Text splitted to sentences.\n",
      "['Hello world!']\n",
      " > Processing time: 8.423449754714966\n",
      " > Real-time factor: 4.532825729487139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Run TTS\n",
    "# ❗ Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\n",
    "# Text to speech list of amplitude values as output\n",
    "wav = tts.tts(text=\"chohvderfowbneeteyf\", speaker_wav=\"sample_sub-5435_ses-t1_audio.wav\", language=\"en\")\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=\"chohvderfowbneeteyf\", speaker_wav=\"sample_sub-5435_ses-t1_audio.wav\", language=\"en\", file_path=\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2694289-2d0b-44c3-9f9d-c582eb17936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined=pd.read_csv(f'/nese/mit/group/sig/projects/readnet/rer_kaggle/rer_kaggle.csv') #load kaggle csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b246c4a4-2ab4-4d31-8bd9-3b2a138f19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_items = combined['item_name'].unique().tolist() #get unique items for estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73a070-b095-4bdc-9dd8-15b6b93e2ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cc69d31-75db-433a-a693-1d8945c3ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['kuhcheyvap']\n",
      " > Processing time: 9.189632654190063\n",
      " > Real-time factor: 4.681871534771047\n",
      " > Text splitted to sentences.\n",
      "['moid']\n",
      " > Processing time: 5.8182384967803955\n",
      " > Real-time factor: 4.815771728754044\n",
      " > Text splitted to sentences.\n",
      "['vergowfduhboik']\n",
      " > Processing time: 20.49567675590515\n",
      " > Real-time factor: 4.315600386437247\n",
      " > Text splitted to sentences.\n",
      "['vugoobuhcheen']\n",
      " > Processing time: 11.795343160629272\n",
      " > Real-time factor: 4.416043817778379\n",
      " > Text splitted to sentences.\n",
      "['toovhohgneeb']\n",
      " > Processing time: 10.930199146270752\n",
      " > Real-time factor: 4.4186508355689\n",
      " > Text splitted to sentences.\n",
      "['gahyfmowb']\n",
      " > Processing time: 21.554641008377075\n",
      " > Real-time factor: 4.357487111584224\n",
      " > Text splitted to sentences.\n",
      "['kahybeymookdowb']\n",
      " > Processing time: 18.854021549224854\n",
      " > Real-time factor: 4.400202954703726\n",
      " > Text splitted to sentences.\n",
      "['kefnuhvohkmerforb']\n",
      " > Processing time: 50.71315789222717\n",
      " > Real-time factor: 4.403015858390069\n",
      " > Text splitted to sentences.\n",
      "['meevteyfohg']\n",
      " > Processing time: 9.785298109054565\n",
      " > Real-time factor: 4.50563446593412\n",
      " > Text splitted to sentences.\n",
      "['goomdachahytowb']\n",
      " > Processing time: 10.702090501785278\n",
      " > Real-time factor: 4.517249149394437\n"
     ]
    }
   ],
   "source": [
    "# generate 10 wav files to see how they sound\n",
    "lengths=[]\n",
    "for u in unique_items[:10]:\n",
    "    # wav = tts.tts(text=u, speaker_wav=\"sample_sub-5435_ses-t1_audio.wav\", language=\"en\")\n",
    "    tts.tts_to_file(text=u, speaker_wav=\"sample_sub-5435_ses-t1_audio.wav\", language=\"en\", file_path=f\"{u}.wav\")\n",
    "    lengths.append(len(wav)/24000) # this is the length in seconds since it has 24k sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda1c8f9-ef7b-439e-a438-f4c28870fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on all of the unique item names\n",
    "lengths=[]\n",
    "for u in unique_items:\n",
    "    wav = tts.tts(text=u, speaker_wav=\"sample_sub-5435_ses-t1_audio.wav\", language=\"en\")\n",
    "    lengths.append(len(wav)/24000) # this is the length in seconds since it has 24k sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05de14b-3a18-4a7f-afb0-4ed0dacc0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'item_name': unique_items, 'estimated_length': lengths}\n",
    "# create a dataframe from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "# save the dataframe as a CSV file\n",
    "df.to_csv('coqui_length_estimates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ebdc8-98d3-4b5a-8e5a-a7120874bf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
